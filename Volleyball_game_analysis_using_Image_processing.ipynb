{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqw7QcNg7XhxGTVMO4p+gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheikhi-a/Animated-Visualization/blob/main/Volleyball_game_analysis_using_Image_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python mediapipe numpy scikit-learn\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "p9l3k-LozyZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400ea68b-43cf-4b9e-835e-c3791b6f0ba1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(os.listdir('/content'))  # List all files in content directory\n",
        "video_path = '/content/volmatch2.mp4'  # Update with your file name\n",
        "\n",
        "\n",
        "def extract_frames(video_path, output_dir='/content/frames'):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_path = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {frame_count} frames to {output_dir}\")\n",
        "\n",
        "extract_frames(video_path)\n",
        "\n",
        "\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "def detect_keypoints_from_frames(frame_dir, output_csv='/content/keypoints.csv'):\n",
        "    data = []\n",
        "    for frame_file in sorted(os.listdir(frame_dir)):\n",
        "        frame_path = os.path.join(frame_dir, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "\n",
        "        # Convert to RGB and detect pose landmarks\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = pose.process(rgb_frame)\n",
        "\n",
        "        if results.pose_landmarks:\n",
        "            keypoints = [(lm.x, lm.y) for lm in results.pose_landmarks.landmark]\n",
        "            flattened_keypoints = [coord for point in keypoints for coord in point]  # Flatten list\n",
        "            data.append([frame_file] + flattened_keypoints)\n",
        "\n",
        "    # Save keypoints to CSV\n",
        "    num_keypoints = len(data[0]) - 1  # Exclude frame column\n",
        "    columns = ['Frame'] + [f'Keypoint_{i}' for i in range(num_keypoints)]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Keypoints saved to {output_csv}\")\n",
        "\n",
        "detect_keypoints_from_frames('/content/frames')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE6omjkARU2S",
        "outputId": "d0f9e9c3-448e-46dd-c5d4-7fb86dc576d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'volmatch2.mp4', 'frames', 'sample_data']\n",
            "Extracted 363 frames to /content/frames\n",
            "Keypoints saved to /content/keypoints.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frame_at_second(video_path, specific_second):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_number = specific_second * fps\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    return frame if ret else None\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "def detect_keypoints(frame):\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(rgb_frame)\n",
        "    if results.pose_landmarks:\n",
        "        keypoints = [(lm.x, lm.y) for lm in results.pose_landmarks.landmark]\n",
        "        return keypoints\n",
        "    return None\n",
        "EXPECTED_NUM_KEYPOINTS = 33\n",
        "\n",
        "def compute_features(keypoints):\n",
        "    if not keypoints or len(keypoints) != EXPECTED_NUM_KEYPOINTS:\n",
        "        keypoints = keypoints[:EXPECTED_NUM_KEYPOINTS] + [(0, 0)] * (EXPECTED_NUM_KEYPOINTS - len(keypoints))\n",
        "    features = []\n",
        "    for i in range(EXPECTED_NUM_KEYPOINTS - 1):\n",
        "        for j in range(i + 1, EXPECTED_NUM_KEYPOINTS):\n",
        "            distance = np.linalg.norm(np.array(keypoints[i]) - np.array(keypoints[j]))\n",
        "            features.append(distance)\n",
        "    return features[:528]\n",
        "\n",
        "np.random.seed(42)\n",
        "dummy_data = np.random.rand(100, 528)\n",
        "dummy_labels = np.random.choice([\"Zone 2\", \"Zone 4\"], 100)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dummy_data, dummy_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "def predict_next_spike_zone(video_path, specific_second):\n",
        "    frame = get_frame_at_second(video_path, specific_second)\n",
        "    if frame is None:\n",
        "        return \"Could not extract frame at the specified second.\"\n",
        "    keypoints = detect_keypoints(frame)\n",
        "    if not keypoints:\n",
        "        return \"Could not detect keypoints in the frame.\"\n",
        "    features = compute_features(keypoints)\n",
        "    if not features:\n",
        "        return \"Features could not be computed from keypoints.\"\n",
        "    prediction = model.predict([features])[0]\n",
        "    return f\"Predicted Zone for Next Spike: {prediction}\"\n",
        "\n",
        "video_path = \"/content/volmatch2.mp4\" # this is my video\n",
        "specific_second = 13 # this is my specific time\n",
        "\n",
        "result = predict_next_spike_zone(video_path, specific_second)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDB2wMvBRPZa",
        "outputId": "47d966a6-2724-4a69-f7cd-60a4505e1447"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Zone for Next Spike: Zone 4\n"
          ]
        }
      ]
    }
  ]
}